"""Update all annotation JSON with the new properties related to enrichment table

Revision ID: 9ab4ceb163b3
Revises: 78e45b7aa53e
Create Date: 2021-03-12 18:20:42.214864

"""
from alembic import context
from alembic import op
import sqlalchemy as sa
from sqlalchemy.sql import table, column
from sqlalchemy.dialects import postgresql
from sqlalchemy.orm.session import Session

from migrations.utils import window_chunk
from neo4japp.models import Files

# revision identifiers, used by Alembic.
revision = '9ab4ceb163b3'
down_revision = '78e45b7aa53e'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    # ### end Alembic commands ###
    if context.get_x_argument(as_dictionary=True).get('data_migrate', None):
        data_upgrades()


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###
    # NOTE: In practice perfect downgrades are difficult and in some cases
    # impossible! It is more practical to use database backups/snapshots to
    # "downgrade" the database. Changes to the database that we intend to
    # push to production should always be added to a NEW migration.
    # (i.e. "downgrade forward"!)


def data_upgrades():
    """Add optional data upgrade migrations here"""
    conn = op.get_bind()
    session = Session(conn)

    tableclause = table(
        'files',
        column('id', sa.Integer),
        column('annotations', postgresql.JSONB),
        column('mime_type', sa.String))

    files = conn.execution_options(stream_results=True).execute(sa.select([
        tableclause.c.id,
        tableclause.c.annotations
    ]).where(
        sa.and_(
            sa.or_(
                tableclause.c.mime_type == 'application/pdf',
                tableclause.c.mime_type == 'vnd.lifelike.document/enrichment-table'
            ),
            tableclause.c.annotations != '[]'
        )
    ))

    for chunk in window_chunk(files, 25):
        collected = []
        for fid, file_annotations in chunk:
            try:
                annotations_list = file_annotations['documents'][0]['passages'][0]['annotations']
            except TypeError:
                # probably enrichment annotations w/ old format
                collected.append({'id': fid, 'annotations': None})
                continue

            updated_annotations = []
            for annotation in annotations_list:
                annotation['enrichmentGene'] = ''
                annotation['enrichmentDomain'] = {'domain': '', 'subDomain': ''}
                updated_annotations.append(annotation)

            file_annotations['documents'][0]['passages'][0]['annotations'] = updated_annotations
            collected.append({'id': fid, 'annotations': file_annotations})
        try:
            session.bulk_update_mappings(Files, collected)
            session.commit()
        except Exception:
            session.rollback()
            raise


def data_downgrades():
    """Add optional data downgrade migrations here"""
    pass
